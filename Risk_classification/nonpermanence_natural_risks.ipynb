{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe4HrUriIbUmWWYkvFVSvQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inesbsilveira/hummingbirds/blob/main/Risk_classification/nonpermanence_natural_risks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeSqVqLd6-OP"
      },
      "outputs": [],
      "source": [
        "!pip install geemap\n",
        "!pip install geojson"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Polygon, MultiPolygon, mapping\n",
        "from shapely.validation import make_valid\n",
        "import geojson\n",
        "import ee\n",
        "import geemap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import ee\n",
        "import datetime\n",
        "import math\n",
        "from math import tan\n",
        "import folium\n",
        "import statistics"
      ],
      "metadata": {
        "id": "qqKU2zuB7AFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_project = 'ee-ineshummingbirds'\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project= my_project)"
      ],
      "metadata": {
        "id": "4pMamVHN7BuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the period of time for temperature and precipitation\n",
        "start_date = '2024-01-01'\n",
        "end_date = '2024-12-31'\n",
        "wf_startDate = '2000-01-01'\n",
        "wf_endDate = '2024-12-31'"
      ],
      "metadata": {
        "id": "tL3im97z7DY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if the input is a shapefile\n",
        "project_name = 'Talia'\n",
        "input_shp = \"ProjectArea_Talia1_reprojected4326.shp\"\n",
        "gdf = gpd.read_file(input_shp).to_crs('EPSG:4326')\n",
        "region = geemap.geopandas_to_ee(gdf)"
      ],
      "metadata": {
        "id": "MbCYffwW7FJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FUNCTIONS\n",
        "# Count the number of days with at least one pixel exceeding the threshold\n",
        "def count_hot_days(image):\n",
        "    mask = image.reduceRegion(\n",
        "        reducer=ee.Reducer.anyNonZero(),\n",
        "        geometry=region,\n",
        "        scale=1000,\n",
        "        maxPixels=1e8\n",
        "    )\n",
        "    is_above = ee.Algorithms.If(mask.get('temperature_2m'), 1, 0)\n",
        "    return ee.Feature(None, {'date': image.get('system:time_start'), 'day_above_32': is_above})\n",
        "\n",
        "def count_flood_events(year):\n",
        "    start_date = ee.Date.fromYMD(year, 1, 1)\n",
        "    end_date = ee.Date.fromYMD(year, 12, 31)\n",
        "\n",
        "    yearly_floods = (gfd.filterDate(start_date, end_date)\n",
        "                      .select('flooded')\n",
        "                      .map(lambda img: img.gt(0).And(jrc.Not()))\n",
        "                      .sum()\n",
        "                      .gt(0))\n",
        "\n",
        "    clipped_flood = yearly_floods.clip(region)\n",
        "\n",
        "    flood_check = clipped_flood.reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=region.geometry(),\n",
        "        scale=500,\n",
        "        maxPixels=1e8\n",
        "    )\n",
        "\n",
        "    return ee.Feature(None, {'year': year, 'flood_count': flood_check.get('flooded')})\n",
        "\n",
        "def get_shapefile_centroid(gdf):\n",
        "    if gdf.crs is None or gdf.crs.is_projected:\n",
        "        gdf = gdf.to_crs(epsg=4326)  # Convert to WGS84 (lat/lon)\n",
        "\n",
        "    #centroid = gdf.unary_union.centroid\n",
        "    centroid = gdf.geometry.union_all().centroid\n",
        "    return centroid.y, centroid.x  # (latitude, longitude)\n",
        "\n",
        "def get_best_crs(latitude, longitude):\n",
        "    utm_zone = int((180 + longitude) / 6) + 1\n",
        "    return f\"EPSG:{32600 + utm_zone if latitude >= 0 else 32700 + utm_zone}\"\n",
        "\n",
        "# Define slope class ranges\n",
        "def classify_slope(slope):\n",
        "    return (slope\n",
        "            .where(slope.lte(15), 1)   # Flat to very gently sloping (Very low)\n",
        "            .where(slope.gt(15).And(slope.lte(30)), 2)  # Gently sloping (Low)\n",
        "            .where(slope.gt(30), 3))  # Steep (Extremely high)\n",
        "\n",
        "# Compute area per class\n",
        "def compute_area(class_value, region):\n",
        "    area = area_per_pixel.updateMask(slope_classified.eq(class_value))\n",
        "    total_area = area.reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=region,\n",
        "        scale=30,\n",
        "        maxPixels=1e13\n",
        "    ).getInfo()\n",
        "    return total_area['area']\n",
        "\n",
        "# Create a function to process burned area by year\n",
        "def process_year(n,region):\n",
        "    # Calculate the start and end date for each year\n",
        "    ini = startDate.advance(n, 'year')\n",
        "    end = ini.advance(1, 'year')\n",
        "\n",
        "    # Filter the burned area collection for the given year\n",
        "    result = sst.filterDate(ini, end)\n",
        "    result = result.max().set('system:time_start', ini)\n",
        "\n",
        "    # Get the burned area (where BurnDate is not 0) and mask it\n",
        "    result = ee.Image.pixelArea() \\\n",
        "               .divide(10000) \\\n",
        "               .updateMask(result.neq(0))  # Mask out non-burned areas\n",
        "\n",
        "    # Sum the area of burned forest for the year\n",
        "    result = result.reduceRegion(\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        geometry=region,\n",
        "        scale=500,\n",
        "        maxPixels=1e12,\n",
        "        tileScale=4\n",
        "    )\n",
        "\n",
        "    # Extract the area burned in the forest for that year\n",
        "    burnedArea = result.get('area')\n",
        "\n",
        "    # Return the area burned in the forest for that year\n",
        "    return ee.Feature(None, {'burned_area_ha': burnedArea})\n",
        "\n",
        "# Process burned area per year\n",
        "def process_year1(n):\n",
        "    ini = startDate.advance(n, 'year')\n",
        "    end = ini.advance(1, 'year')\n",
        "\n",
        "    result = sst.filterDate(ini, end).max()\n",
        "\n",
        "    # Ensure burned areas are correctly masked\n",
        "    result = result.updateMask(result.gt(0))  # Keep only burned pixels\n",
        "\n",
        "    # Compute burned area in hectares\n",
        "    burned_area = ee.Image.pixelArea() \\\n",
        "                    .divide(10000) \\\n",
        "                    .updateMask(result) \\\n",
        "                    .reduceRegion(\n",
        "                        reducer=ee.Reducer.sum(),\n",
        "                        geometry=region,\n",
        "                        scale=500,\n",
        "                        maxPixels=1e12\n",
        "                    )\n",
        "\n",
        "    return ee.Feature(None, {\n",
        "        'year': ini.get('year'),  # Ensure year is stored correctly\n",
        "        'burned_area_ha': burned_area.get('area')\n",
        "    })\n",
        "\n",
        "class color:\n",
        "   PURPLE = '\\033[95m'\n",
        "   CYAN = '\\033[96m'\n",
        "   DARKCYAN = '\\033[36m'\n",
        "   BLUE = '\\033[94m'\n",
        "   GREEN = '\\033[92m'\n",
        "   YELLOW = '\\033[93m'\n",
        "   RED = '\\033[91m'\n",
        "   BOLD = '\\033[1m'\n",
        "   UNDERLINE = '\\033[4m'\n",
        "   END = '\\033[0m'\n",
        "\n",
        "# Classify risk based on the average yearly extreme heat days\n",
        "def classify_risk(total_days):\n",
        "    if total_days < 30:\n",
        "        return 'Low risk'\n",
        "    elif total_days <= 90:\n",
        "        return 'Medium risk'\n",
        "    else:\n",
        "        return 'High risk'\n",
        "\n",
        "# Function to remove duplicates based on the date within each collection\n",
        "def remove_duplicates(collection):\n",
        "    return collection.map(lambda image: image.set('date', ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'))).distinct('date')\n",
        "\n",
        "# Apply threshold to the averaged collection\n",
        "def apply_threshold(image):\n",
        "    thresholdImage = image.gt(thresholdK)  # Identify pixels above 32Â°C\n",
        "    return thresholdImage.set('system:time_start', image.get('system:time_start'))\n",
        "\n",
        "\n",
        "# Count the number of days where at least one pixel exceeded the threshold\n",
        "def count_days_above_35(image):\n",
        "    mask = image.reduceRegion(\n",
        "        reducer=ee.Reducer.anyNonZero(),\n",
        "        geometry=region,\n",
        "        scale=5000,\n",
        "        bestEffort=True\n",
        "    )\n",
        "\n",
        "    isAbove = ee.Algorithms.If(mask.get('tasmax'), 1, 0)\n",
        "\n",
        "    return ee.Feature(None, {'date': image.get('system:time_start'), 'day_above_32': isAbove})\n",
        "\n",
        "# Function to compute the average image at a given index\n",
        "def mean_image_list(collections, indices):\n",
        "    def compute_mean(i):\n",
        "        images = [ee.Image(collection.get(i)) for collection in collections]\n",
        "        mean_img = ee.ImageCollection(images).mean()\n",
        "        return mean_img.set('system:time_start', images[0].get('system:time_start'))\n",
        "\n",
        "    return indices.map(compute_mean)\n",
        "\n",
        "# Function to filter images by season\n",
        "def filter_by_season(image_collection, start_month, end_month):\n",
        "    return image_collection.filter(ee.Filter.calendarRange(start_month, end_month, 'month'))\n",
        "\n",
        "# Extract the month and year from the date to group by month\n",
        "def add_month_year(image):\n",
        "    date = ee.Date(image.get('system:time_start'))\n",
        "    month = date.get('month')\n",
        "    year = date.get('year')\n",
        "    return image.set('month', month).set('year', year)\n",
        "\n",
        "# Group by month and calculate the mean for both temperature and precipitation\n",
        "def calculate_monthly_means(month):\n",
        "    # Filter the datasets by the current month\n",
        "    tempData = tempWithMonth.filter(ee.Filter.eq('month', month))\n",
        "    precipData = precipWithMonth.filter(ee.Filter.eq('month', month))\n",
        "\n",
        "    # Calculate the mean temperature for that month across all years\n",
        "    tempMean = tempData.mean().reduceRegion(\n",
        "        reducer=ee.Reducer.mean(),\n",
        "        geometry=region,\n",
        "        scale=10000,  # Adjust based on your area of interest\n",
        "        maxPixels=1e8\n",
        "    )\n",
        "\n",
        "    # Calculate the mean precipitation for that month across all years\n",
        "    precipMean = precipData.mean().reduceRegion(\n",
        "        reducer=ee.Reducer.mean(),\n",
        "        geometry=region,\n",
        "        scale=10000,  # Adjust based on your area of interest\n",
        "        maxPixels=1e8\n",
        "    )\n",
        "\n",
        "    # Convert temperature from Kelvin to Celsius (subtract 273.15)\n",
        "    temperatureCelsius = ee.Number(tempMean.get('temperature_2m')).subtract(273.15)\n",
        "\n",
        "    # Convert precipitation from meters to millimeters (multiply by 1000)\n",
        "    precipitationMillimeters = ee.Number(precipMean.get('total_precipitation_sum')).multiply(1000)\n",
        "\n",
        "    # Create a feature with the month, temperature in Celsius, and precipitation in millimeters\n",
        "    return ee.Feature(None, {\n",
        "        'month': month,\n",
        "        'mean_temperature_celsius': temperatureCelsius,\n",
        "        'mean_precipitation_mm': precipitationMillimeters\n",
        "    })"
      ],
      "metadata": {
        "id": "y-mFzOvD7HMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DEM\n",
        "dem_dataset = ee.Image('USGS/SRTMGL1_003').clip(region)\n",
        "\n",
        "#DEM\n",
        "dem_dataset = ee.Image('USGS/SRTMGL1_003').clip(region)\n",
        "elevation = dem_dataset.select('elevation')\n",
        "#Elevation\n",
        "#calculate mean, min and max elevation value\n",
        "elevation_stats = elevation.reduceRegion(\n",
        "    reducer=ee.Reducer.min().combine(ee.Reducer.max(), None, True).combine(ee.Reducer.mean(), None, True),\n",
        "    geometry=region.geometry(),\n",
        "    scale=30,\n",
        "    bestEffort=True\n",
        ")\n",
        "\n",
        "elevation_min_value = elevation_stats.get('elevation_min').getInfo()\n",
        "elevation_max_value = elevation_stats.get('elevation_max').getInfo()\n",
        "elevation_mean_value = elevation_stats.get('elevation_mean').getInfo()\n",
        "\n",
        "#Slope\n",
        "#calculate the slope\n",
        "slope = ee.Terrain.slope(elevation).clip(region)\n",
        "\n",
        "slope_stats = slope.reduceRegion(\n",
        "    reducer=ee.Reducer.min().combine(ee.Reducer.max(), None, True).combine(ee.Reducer.mean(), None, True).combine(ee.Reducer.mode(), None, True),\n",
        "    geometry=region,\n",
        "    scale=30,  # change resolution if needed\n",
        "    maxPixels=1e13\n",
        ")\n",
        "\n",
        "slope_min = slope_stats.get('slope_min').getInfo()\n",
        "slope_max = slope_stats.get('slope_max').getInfo()\n",
        "slope_mean = slope_stats.get('slope_mean').getInfo()\n",
        "slope_mode = slope_stats.get('slope_mode').getInfo()\n",
        "\n",
        "#convert from degrees to percentage\n",
        "slope_min_percentage = math.tan(math.radians(slope_min)) * 100\n",
        "slope_max_percentage = math.tan(math.radians(slope_max)) * 100\n",
        "slope_mean_percentage = math.tan(math.radians(slope_mean)) * 100\n",
        "slope_mode_percentage = math.tan(math.radians(slope_mode)) * 100\n",
        "\n",
        "# Classify the risk of erosion based on degrees\n",
        "if slope_mode_percentage < 15:\n",
        "  risk_level_erosion = \"Low risk\"\n",
        "elif slope_mode_percentage <= 30:\n",
        "  risk_level_erosion = \"Medium risk\"\n",
        "else:\n",
        "  risk_level_erosion = \"High risk\"\n",
        "\n",
        "print(color.BOLD + 'ELEVATION AND SLOPE' + color.END)\n",
        "print(f'Mean elevation: {elevation_mean_value:.0f} m')\n",
        "print(f'Minimum elevation: {elevation_min_value:.0f} m')\n",
        "print(f'Maximum elevation: {elevation_max_value:.0f} m')\n",
        "print(f'Most common slope value: {slope_mode:.2f}Â°')\n",
        "print(f'Mean slope: {slope_mean:.2f}Â°')\n",
        "print(f'Minimum slope: {slope_min:.2f}Â°')\n",
        "print(f'Maximum slope: {slope_max:.2f}Â°')\n",
        "print(color.PURPLE + f\"Erosion Risk Level: {risk_level_erosion}\" + color.END)\n",
        "\n",
        "# Apply classification\n",
        "slope_classified = classify_slope(slope)\n",
        "\n",
        "# Convert to area (hectares)\n",
        "area_per_pixel = ee.Image.pixelArea().divide(10000)  # Convert to hectares\n",
        "\n",
        "# Create table data\n",
        "classes = [\n",
        "    (1, \"0-15\", \"Flat to very gently\", \"Low\"),\n",
        "    (2, \"15-30\", \"Gently slope\", \"Medium\"),\n",
        "    (3, \">30\", \"Sloping\", \"High\")\n",
        "]\n",
        "\n",
        "# Compute areas\n",
        "data = []\n",
        "total_land = sum([compute_area(c[0], region) for c in classes])  # Total land area\n",
        "\n",
        "for c in classes:\n",
        "    area_ha = compute_area(c[0], region)\n",
        "    percentage = (area_ha / total_land) * 100 if total_land else 0\n",
        "    data.append([c[0], c[1], c[2], c[3], f\"{area_ha:,.2f}\", f\"{percentage:.1f}%\"])\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"No\", \"Classes (Â°)\", \"Characteristics\", \"Susceptibility\", \"Area (ha)\", \"Area (%)\"])\n",
        "\n",
        "# Display the table\n",
        "print(df)"
      ],
      "metadata": {
        "id": "7BbHN8MI7JEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define visualization parameters for a green-yellow-green color scheme\n",
        "vis_params = {\n",
        "    'min': elevation_min_value,\n",
        "    'max': elevation_max_value,\n",
        "    'palette': ['green', 'yellow', 'red']  # Green for low, yellow for mid, green for high\n",
        "}\n",
        "\n",
        "# Create a map centered on the shapefile region\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(elevation, vis_params, \"Elevation Map\")\n",
        "fc = region.style(fillColor='00000000')\n",
        "Map.addLayer(fc, {}, \"Transparent Vector\")\n",
        "Map.centerObject(region, 11)\n",
        "# Add a continuous color gradient legend\n",
        "Map.add_colorbar(\n",
        "    vis_params=vis_params,\n",
        "    label=\"Elevation (m)\",\n",
        "    orientation=\"horizontal\"\n",
        ")\n",
        "# Display the map\n",
        "Map"
      ],
      "metadata": {
        "id": "u21ugUNQ7Na9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tif to Google Drive\n",
        "geemap.ee_export_image_to_drive(\n",
        "    elevation, description=f'elevation_{project_name}', region=region.geometry(), scale=30\n",
        ")"
      ],
      "metadata": {
        "id": "De4XLdgq7PhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#temperature - ERA5-Land dataset (temperature in Kelvin)\n",
        "temp_dataset = (ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY')\n",
        "                .filterDate(start_date, end_date)\n",
        "                .select('temperature_2m'))\n",
        "\n",
        "# Calculate the mean, min, and max annual temperature\n",
        "mean_temp = temp_dataset.mean().clip(region)\n",
        "min_temp = temp_dataset.min().clip(region)\n",
        "max_temp = temp_dataset.max().clip(region)\n",
        "\n",
        "# Convert temperature from Kelvin to Celsius\n",
        "mean_temp_celsius = mean_temp.subtract(273.15)\n",
        "min_temp_celsius = min_temp.subtract(273.15)\n",
        "max_temp_celsius = max_temp.subtract(273.15)\n",
        "\n",
        "# Calculate the average, min, and max temperature over the region\n",
        "temp_stats = mean_temp_celsius.reduceRegion(\n",
        "    reducer=ee.Reducer.mean(),\n",
        "    geometry=region.geometry(),\n",
        "    scale=1000,\n",
        "    bestEffort=True\n",
        ")\n",
        "\n",
        "min_stats = min_temp_celsius.reduceRegion(\n",
        "    reducer=ee.Reducer.min(),\n",
        "    geometry=region.geometry(),\n",
        "    scale=1000,\n",
        "    bestEffort=True\n",
        ")\n",
        "\n",
        "max_stats = max_temp_celsius.reduceRegion(\n",
        "    reducer=ee.Reducer.max(),\n",
        "    geometry=region.geometry(),\n",
        "    scale=1000,\n",
        "    bestEffort=True\n",
        ")\n",
        "\n",
        "# Extract and print temperature values\n",
        "avg_temp = temp_stats.get('temperature_2m').getInfo()\n",
        "min_temp_value = min_stats.get('temperature_2m').getInfo()\n",
        "max_temp_value = max_stats.get('temperature_2m').getInfo()\n",
        "\n",
        "print(color.BOLD + 'TEMPERATURE 2024' + color.END)\n",
        "print(f'Average Annual Temperature (Â°C): {avg_temp:.2f}')\n",
        "print(f'Minimum Annual Temperature (Â°C): {min_temp_value:.2f}')\n",
        "print(f'Maximum Annual Temperature (Â°C): {max_temp_value:.2f}')\n"
      ],
      "metadata": {
        "id": "i4v0V9R17Rqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the dataset (ERA5-Land hourly temperature data)\n",
        "dataset = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \\\n",
        "                .filterDate('2024-01-01', '2024-12-31')\n",
        "\n",
        "# Select the temperature variable (temperature_2m) and convert from Kelvin to Celsius\n",
        "temperature = dataset.select('temperature_2m').map(lambda img: img.subtract(273.15))\n",
        "\n",
        "# Calculate the mean temperature over the time period\n",
        "temperature_mean = temperature.mean()\n",
        "\n",
        "# Clip the temperature data to the region of interest\n",
        "temperature_clipped = temperature_mean.clip(region)\n",
        "\n",
        "# Calculate the min and max temperature values over the region\n",
        "min_temp = temperature_mean.reduceRegion(\n",
        "    reducer=ee.Reducer.min(),\n",
        "    geometry=region,  # Provide the region for aggregation\n",
        "    scale=1000,       # You can adjust the scale (in meters) based on your dataset resolution\n",
        "    maxPixels=1e8     # Limit on the number of pixels to be processed\n",
        ").getInfo()\n",
        "\n",
        "max_temp = temperature_mean.reduceRegion(\n",
        "    reducer=ee.Reducer.max(),\n",
        "    geometry=region,  # Provide the region for aggregation\n",
        "    scale=1000,       # Same scale as above\n",
        "    maxPixels=1e8     # Same pixel limit\n",
        ").getInfo()\n",
        "\n",
        "# Set the visualization parameters based on min and max temperatures\n",
        "visualization = {\n",
        "    'min': min_temp['temperature_2m'],\n",
        "    'max': max_temp['temperature_2m'],\n",
        "    'palette': ['#ffffb2', '#fecc5c', '#fd8d3c', '#e31a1c']\n",
        "}\n",
        "\n",
        "# Create a folium map centered around the region\n",
        "\n",
        "# Add the temperature layer to the map\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(temperature_clipped, visualization, \"Temperature Map\")\n",
        "fc = region.style(fillColor='00000000')\n",
        "Map.addLayer(fc, {}, \"Transparent Vector\")\n",
        "Map.centerObject(region, 11)\n",
        "# Display the map\n",
        "Map\n"
      ],
      "metadata": {
        "id": "4R7tdPKW7UNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tif to Google Drive\n",
        "geemap.ee_export_image_to_drive(\n",
        "    temperature_clipped, description='average_temp_calao_map', region=region.geometry(), scale=30\n",
        ")"
      ],
      "metadata": {
        "id": "Kh4lmbEV7WKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2024\n",
        "# Load the ERA5-Land Daily Aggregated dataset\n",
        "temp_dataset = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR') \\\n",
        "    .filterBounds(region) \\\n",
        "    .filterDate(start_date, end_date) \\\n",
        "    .select('temperature_2m_max')  # Select daily max temperature\n",
        "\n",
        "# Define the temperature threshold (35Â°C in Kelvin)\n",
        "temp_threshold = ee.Number(35).add(273.15)\n",
        "\n",
        "# Count the number of days exceeding 35Â°C\n",
        "hot_days = temp_dataset.map(lambda image: image.gt(temp_threshold).set('date', image.date())).sum()\n",
        "\n",
        "# Reduce the count over the region (AOI)\n",
        "hot_days_count_24 = hot_days.reduceRegion(\n",
        "    reducer=ee.Reducer.mean(),\n",
        "    geometry=region,\n",
        "    scale=1000,\n",
        "    maxPixels=1e9\n",
        ")\n",
        "\n",
        "\n",
        "# 2050\n",
        "models = ['GFDL-ESM4', 'IPSL-CM6A-LR', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'UKESM1-0-LL']\n",
        "hot_days_list = []\n",
        "\n",
        "for model in models:\n",
        "  temp_dataset = ee.ImageCollection('NASA/GDDP-CMIP6') \\\n",
        "      .filter(ee.Filter.date('2050-01-01', '2050-12-31')) \\\n",
        "      .filter(ee.Filter.eq('model', model)) \\\n",
        "      .select('tasmax')\n",
        "\n",
        "  # Define the temperature threshold (35Â°C in Kelvin)\n",
        "  temp_threshold = ee.Number(35).add(273.15)\n",
        "\n",
        "  # Count the number of days exceeding 35Â°C\n",
        "  hot_days = temp_dataset.map(lambda image: image.gt(temp_threshold).set('date', image.date())).sum()\n",
        "\n",
        "  # Reduce the count over the region (AOI)\n",
        "  hot_days_count = hot_days.reduceRegion(\n",
        "      reducer=ee.Reducer.mean(),\n",
        "      geometry=region,\n",
        "      scale=1000,\n",
        "      maxPixels=1e9\n",
        "  )\n",
        "  hot_days_list.append(hot_days_count.get('tasmax').getInfo())\n",
        "  # Print the result for 2024\n",
        "  #print('Number of days above 35C:', hot_days_count.get('tasmax').getInfo())\n",
        "\n",
        "average = statistics.mean(hot_days_list)\n",
        "\n",
        "# Classify risk\n",
        "if average < 30:\n",
        "    risk_level = \"Low risk\"\n",
        "elif average > 90:\n",
        "    risk_level = \"High risk\"\n",
        "else:\n",
        "    risk_level = \"Medium risk\"\n",
        "\n",
        "print(color.BOLD + 'THERMAL STRESS 2050' + color.END)\n",
        "print('Number of days with temperatures above 35C in 2024:', int(hot_days_count_24.get('temperature_2m_max').getInfo()))\n",
        "print('Number of days with temperatures above 35C in 2050:', f'{average:.0f}')\n",
        "print(color.PURPLE + f\"Thermal Stress Risk Level: {risk_level}\" + color.END)\n"
      ],
      "metadata": {
        "id": "jQKu86WE7Ydm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CHIRPS Daily precipitation data\n",
        "precip_dataset = (ee.ImageCollection('UCSB-CHG/CHIRPS/PENTAD')\n",
        "          .filterDate(start_date, end_date))\n",
        "\n",
        "# Sum precipitation over the selected period\n",
        "total = precip_dataset.reduce(ee.Reducer.sum())\n",
        "\n",
        "# Compute mean precipitation within the given region\n",
        "stats = total.reduceRegion(\n",
        "    reducer=ee.Reducer.mean(),\n",
        "    geometry=region,\n",
        "    scale=5000\n",
        ")\n",
        "\n",
        "# Define the dry and wet seasons\n",
        "dry_season_1stmonth = 12\n",
        "dry_season_lastmonth = 2\n",
        "wet_season_1stmonth = 3\n",
        "wet_season_lastmonth = 11\n",
        "\n",
        "# Filter the dataset for each season\n",
        "dry_season = filter_by_season(precip_dataset, dry_season_1stmonth, dry_season_lastmonth).filterDate(start_date, end_date)\n",
        "wet_season = filter_by_season(precip_dataset, wet_season_1stmonth, wet_season_lastmonth).filterDate(start_date, end_date)\n",
        "\n",
        "# Compute total precipitation sum for dry season\n",
        "total_dry = dry_season.reduce(ee.Reducer.sum()).reduceRegion(\n",
        "    reducer=ee.Reducer.mean(),\n",
        "    geometry=region,\n",
        "    scale=5000\n",
        ")\n",
        "\n",
        "# Compute total precipitation sum for wet season\n",
        "total_wet = wet_season.reduce(ee.Reducer.sum()).reduceRegion(\n",
        "    reducer=ee.Reducer.mean(),\n",
        "    geometry=region,\n",
        "    scale=5000\n",
        ")\n",
        "\n",
        "# Extract the precipitation sum values\n",
        "dry_precip_value = total_dry.getInfo().get('precipitation_sum')\n",
        "wet_precip_value = total_wet.getInfo().get('precipitation_sum')\n",
        "\n",
        "print(color.BOLD + 'PRECIPITATION 2024' + color.END)\n",
        "print(f\"Total Precipitation: {stats.getInfo().get('precipitation_sum'):.2f} mm\")\n",
        "print(f\"Total Dry Season Precipitation: {dry_precip_value:.2f} mm\")\n",
        "print(f\"Total Wet Season Precipitation: {wet_precip_value:.2f} mm\")\n",
        "\n",
        "# Define the time range\n",
        "start_year_prec = 1994\n",
        "end_year_prec = 2024\n",
        "\n",
        "# Load CHIRPS precipitation data\n",
        "chirps = ee.ImageCollection('UCSB-CHG/CHIRPS/PENTAD')\n",
        "\n",
        "# Initialize a list to store the precipitation values for each year\n",
        "annual_precipitation = []\n",
        "\n",
        "# Loop through each year in the range\n",
        "for year in range(start_year_prec, end_year_prec + 1):\n",
        "    # Filter CHIRPS data for the specific year\n",
        "    chirps_year = chirps.filter(ee.Filter.calendarRange(year, year, 'year'))\n",
        "\n",
        "    # Sum precipitation over the selected year\n",
        "    total_year = chirps_year.reduce(ee.Reducer.sum())\n",
        "\n",
        "    # Compute mean precipitation for the year within the given region\n",
        "    stats_year = total_year.reduceRegion(\n",
        "        reducer=ee.Reducer.mean(),\n",
        "        geometry=region,\n",
        "        scale=5000\n",
        "    )\n",
        "\n",
        "    # Extract the total precipitation for the year\n",
        "    yearly_precip = stats_year.get('precipitation_sum')\n",
        "\n",
        "    # Append the result to the list\n",
        "    annual_precipitation.append((year, yearly_precip.getInfo()))\n",
        "\n",
        "# Print out the results\n",
        "#for year, precip in annual_precipitation:\n",
        "    #print(f\"Year {year}: Total Precipitation = {precip:.2f} mm\")\n",
        "\n",
        "# Extract years and precipitation values for plotting\n",
        "years = [year for year, _ in annual_precipitation]\n",
        "precipitation = [precip for _, precip in annual_precipitation]\n",
        "\n",
        "# Calculate mean annual precipitation\n",
        "mean_precipitation = np.mean(precipitation)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Mean Annual Precipitation (1994-2024): {mean_precipitation:.2f} mm\")\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(years, precipitation, color ='#4b8292')\n",
        "plt.title('Annual Total Precipitation (1994 - 2024)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Total Precipitation (mm)')\n",
        "z = np.polyfit(years, precipitation, 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(years, p(years), \"r--\", label=\"Trend Line\", color='#E77577')\n",
        "plt.grid(True)\n",
        "plt.xticks(years, rotation=45)\n",
        "plt.ylim(0, max(precipitation) * 1.1)\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wDw60aan7adk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset (ERA5-Land hourly temperature data)\n",
        "dataset = ee.ImageCollection('UCSB-CHG/CHIRPS/PENTAD') \\\n",
        "                .filterDate('2024-01-01', '2024-12-31')\n",
        "\n",
        "# Sum precipitation over the selected period\n",
        "total = dataset.reduce(ee.Reducer.sum())\n",
        "\n",
        "# Clip the temperature data to the region of interest\n",
        "precipitation = total.clip(region)\n",
        "\n",
        "# Calculate the min and max temperature values over the region\n",
        "min_precip = total.reduceRegion(\n",
        "    reducer=ee.Reducer.min(),\n",
        "    geometry=region,  # Provide the region for aggregation\n",
        "    scale=1000,       # You can adjust the scale (in meters) based on your dataset resolution\n",
        "    maxPixels=1e8     # Limit on the number of pixels to be processed\n",
        ").getInfo()\n",
        "\n",
        "max_precip = total.reduceRegion(\n",
        "    reducer=ee.Reducer.max(),\n",
        "    geometry=region,  # Provide the region for aggregation\n",
        "    scale=1000,       # Same scale as above\n",
        "    maxPixels=1e8     # Same pixel limit\n",
        ").getInfo()\n",
        "\n",
        "# Set the visualization parameters based on min and max temperatures\n",
        "visualization = {\n",
        "    'min': min_precip['precipitation_sum'],\n",
        "    'max': max_precip['precipitation_sum'],\n",
        "    'palette': ['fff7fb', 'ece2f0', 'd0d1e6', 'a6bddb', '67a9cf', '1c9099', '016c59', '014636']\n",
        "\n",
        "}\n",
        "\n",
        "# Create a folium map centered around the region\n",
        "\n",
        "# Add the temperature layer to the map\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(precipitation, visualization, \"Precipitation Map\")\n",
        "fc = region.style(fillColor='00000000')\n",
        "Map.addLayer(fc, {}, \"Transparent Vector\")\n",
        "Map.centerObject(region, 11)\n",
        "# Display the map\n",
        "Map"
      ],
      "metadata": {
        "id": "Cc48EUIx7cW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tif to Google Drive\n",
        "geemap.ee_export_image_to_drive(\n",
        "    precipitation, description='total_precipitation_calao_map', region=region.geometry(), scale=30\n",
        ")"
      ],
      "metadata": {
        "id": "fPL0N5KX7ehD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ERA5 Monthly dataset for temperature and precipitation\n",
        "tempDataset = ee.ImageCollection(\"ECMWF/ERA5_LAND/MONTHLY_AGGR\") \\\n",
        "                .filterDate('1994-01-01', '2024-12-31') \\\n",
        "                .select('temperature_2m')  # Temperature dataset\n",
        "\n",
        "precipDataset = ee.ImageCollection(\"ECMWF/ERA5_LAND/MONTHLY_AGGR\") \\\n",
        "                .filterDate('1994-01-01', '2024-12-31') \\\n",
        "                .select('total_precipitation_sum')  # Precipitation dataset\n",
        "\n",
        "tempWithMonth = tempDataset.map(add_month_year)\n",
        "precipWithMonth = precipDataset.map(add_month_year)\n",
        "\n",
        "# Create a list of months (1 to 12) and calculate the monthly means\n",
        "monthlyMeans = ee.List.sequence(1, 12).map(calculate_monthly_means)\n",
        "\n",
        "# Convert the list of features to a FeatureCollection\n",
        "monthlyMeansFC = ee.FeatureCollection(monthlyMeans)\n",
        "\n",
        "# Print the result to check\n",
        "#print(monthlyMeansFC.getInfo())\n",
        "\n",
        "# Create the combo chart (Bar + Line)\n",
        "# Extract the monthly data from the FeatureCollection\n",
        "features = monthlyMeansFC.getInfo()['features']\n",
        "months = [feature['properties']['month'] for feature in features]\n",
        "temperatures = [feature['properties']['mean_temperature_celsius'] for feature in features]\n",
        "precipitation = [feature['properties']['mean_precipitation_mm'] for feature in features]\n",
        "\n",
        "# Plot the data\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot precipitation as bars\n",
        "ax1.bar(months, precipitation, color='#4b8292', width=0.4, label='Precipitation (mm)', align='center')\n",
        "ax1.set_xlabel('Month')\n",
        "ax1.set_ylabel('Precipitation (mm)', color='#4b8292')\n",
        "ax1.tick_params(axis='y', labelcolor='#4b8292')\n",
        "\n",
        "# Set the y-axis limit for precipitation (0 to 200 mm)\n",
        "ax1.set_ylim(0, 200)\n",
        "\n",
        "# Create a second y-axis for the temperature\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(months, temperatures, color='#E77577', label='Temperature (Â°C)', marker='o', linestyle='-', linewidth=2)\n",
        "ax2.set_ylabel('Temperature (Â°C)', color='#E77577')\n",
        "ax2.tick_params(axis='y', labelcolor='#E77577')\n",
        "\n",
        "# Set the y-axis limit for temperature (0 to 30Â°C)\n",
        "ax2.set_ylim(0, 30)\n",
        "\n",
        "# Set chart title\n",
        "plt.title('Average Monthly Precipitation and Temperature (1994-2024)')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Pd-WqVXq7gYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#floods -  MODIS Global Flood Database (GFD) and JRC permanent water mask\n",
        "gfd = ee.ImageCollection('GLOBAL_FLOOD_DB/MODIS_EVENTS/V1')\n",
        "jrc = (ee.ImageCollection('JRC/GSW1_4/YearlyHistory')\n",
        "       .select('waterClass')\n",
        "       .map(lambda img: img.eq(3))  # Permanent water class\n",
        "       .max())\n",
        "\n",
        "# Define years for flood analysis\n",
        "years = ee.List.sequence(2000, 2018)\n",
        "\n",
        "# Convert flood counts to FeatureCollection\n",
        "flood_counts_fc = ee.FeatureCollection(years.map(count_flood_events))\n",
        "\n",
        "total_floods = flood_counts_fc.aggregate_sum('flood_count').getInfo()\n",
        "\n",
        "# Classify risk\n",
        "if total_floods == 0:\n",
        "    risk_level = \"Low risk\"\n",
        "elif total_floods == 1:\n",
        "    risk_level = \"Medium risk\"\n",
        "else:\n",
        "    risk_level = \"High risk\"\n",
        "\n",
        "print(color.BOLD + 'FLOODS 2000-2018' + color.END)\n",
        "if total_floods > 0:\n",
        "    print('Floods detected in the project area')\n",
        "else:\n",
        "    print('No floods detected in the project area')\n",
        "print('Number of total flood events:', total_floods)\n",
        "#print(f'Flood Risk Level: {risk_level}')\n",
        "print(color.PURPLE + f\"Flood Risk Level: {risk_level}\" + color.END)"
      ],
      "metadata": {
        "id": "RgR7qoYD7iKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drought - SPEI dataset\n",
        "spei_dataset = ee.ImageCollection(\"CSIC/SPEI/2_10\") \\\n",
        "    .filterBounds(region) \\\n",
        "    .filterDate(\"1992-01-01\", \"2022-01-01\")\n",
        "\n",
        "# Compute average SPEI indices\n",
        "spei_avg = spei_dataset.reduce(ee.Reducer.mean()).clip(region).select([\n",
        "    \"SPEI_03_month_mean\", \"SPEI_06_month_mean\", \"SPEI_09_month_mean\", \"SPEI_12_month_mean\"\n",
        "])\n",
        "\n",
        "# Compute drought risk based on SPEI-9\n",
        "chart_data = spei_dataset.map(lambda image:\n",
        "    ee.Feature(None, {\n",
        "        \"Date\": image.get(\"system:time_start\"),\n",
        "        \"SPEI_09_month\": image.select(\"SPEI_09_month\").reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=region.geometry(),\n",
        "            scale=55660,\n",
        "            maxPixels=1e9\n",
        "        ).get(\"SPEI_09_month\")\n",
        "    })\n",
        ")\n",
        "\n",
        "# Convert to FeatureCollection\n",
        "chart_list = chart_data.toList(chart_data.size())\n",
        "print(chart_list.getInfo())\n",
        "# Filter drought events (SPEI-9 < -1.5)\n",
        "drought_events = chart_list.filter(ee.Filter.lt(\"SPEI_09_month\", -1.5))\n",
        "\n",
        "# Compute drought risk percentage\n",
        "total_features = chart_list.size()\n",
        "num_drought_events = drought_events.size()\n",
        "percentage_drought = ee.Number(num_drought_events).divide(total_features).multiply(100)\n",
        "\n",
        "# Classify drought risk\n",
        "risk_level = ee.Algorithms.If(\n",
        "    percentage_drought.lt(5), \"Low risk\",\n",
        "    ee.Algorithms.If(percentage_drought.lt(15), \"Medium risk\", \"High risk\")\n",
        ")\n",
        "\n",
        "percentage_drought = percentage_drought.getInfo()\n",
        "\n",
        "# Print drought risk\n",
        "print(color.BOLD + 'DROUGHT 1992-2022' + color.END)\n",
        "print(f\"Months with severe drought: {percentage_drought:.2f} %\")\n",
        "#print(\"Drought Risk Level:\", risk_level.getInfo())\n",
        "print(color.PURPLE + f\"Drought Risk Level: {risk_level.getInfo()}\" + color.END)\n",
        "\n"
      ],
      "metadata": {
        "id": "kcdkA0CR7kYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buffer the region by 10 km\n",
        "buffered_region = region.geometry().buffer(10000)\n",
        "\n",
        "# Compute average SPEI indices\n",
        "spei_avg = spei_dataset.reduce(ee.Reducer.mean()).clip(region).select([\n",
        "    \"SPEI_03_month_mean\", \"SPEI_06_month_mean\", \"SPEI_09_month_mean\", \"SPEI_12_month_mean\"\n",
        "])\n",
        "\n",
        "# Compute drought risk based on SPEI-9\n",
        "chart_data = spei_dataset.map(lambda image:\n",
        "    ee.Feature(None, {\n",
        "        \"Date\": image.get(\"system:time_start\"),\n",
        "        \"SPEI_09_month\": image.select(\"SPEI_09_month\").reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=buffered_region,\n",
        "            scale=55660,\n",
        "            maxPixels=1e9\n",
        "        ).get(\"SPEI_09_month\")\n",
        "    })\n",
        ")\n",
        "\n",
        "# Convert to FeatureCollection\n",
        "chart_list = chart_data.toList(chart_data.size())\n",
        "\n",
        "# Filter drought events (SPEI-9 < -1.5)\n",
        "drought_events = chart_list.filter(ee.Filter.lt(\"SPEI_09_month\", -1.5))\n",
        "\n",
        "# Compute drought risk percentage\n",
        "total_features = chart_list.size()\n",
        "num_drought_events = drought_events.size()\n",
        "percentage_drought = ee.Number(num_drought_events).divide(total_features).multiply(100)\n",
        "\n",
        "# Classify drought risk\n",
        "risk_level = ee.Algorithms.If(\n",
        "    percentage_drought.lt(5), \"Low risk\",\n",
        "    ee.Algorithms.If(percentage_drought.lt(15), \"Medium risk\", \"High risk\")\n",
        ")\n",
        "\n",
        "percentage_drought = percentage_drought.getInfo()\n",
        "\n",
        "# Print drought risk\n",
        "print(color.BOLD + 'DROUGHT 1992-2022' + color.END)\n",
        "print(f\"Months with severe drought: {percentage_drought:.2f} %\")\n",
        "#print(\"Drought Risk Level:\", risk_level.getInfo())\n",
        "print(color.PURPLE + f\"Drought Risk Level: {risk_level.getInfo()}\" + color.END)\n"
      ],
      "metadata": {
        "id": "BbmQby4Y7msq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert chart_data to a list\n",
        "chart_list = chart_data.aggregate_array(\"Date\").getInfo()\n",
        "spei_values = chart_data.aggregate_array(\"SPEI_09_month\").getInfo()\n",
        "\n",
        "# Convert dates from milliseconds to datetime format\n",
        "dates = pd.to_datetime(chart_list, unit='ms')\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\"Date\": dates, \"SPEI_09_month\": spei_values})\n",
        "# Ensure 'Date' is in datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "count_drought = (df['SPEI_09_month'] < -1.5).sum()\n",
        "print(count_drought)\n",
        "#print(df)\n",
        "\n",
        "# Plot SPEI-9 over time with better handling for many bars\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Create bars - using narrower width for better visibility\n",
        "bars = plt.bar(df['Date'], df[\"SPEI_09_month\"],\n",
        "               width=20,  # Narrower bars to fit 360 of them\n",
        "               color=np.where(df[\"SPEI_09_month\"] < -1.5, 'red', 'b'),  # Color drought values red\n",
        "               label=\"SPEI-9 Month Avg\")\n",
        "\n",
        "threshold = -1.5\n",
        "\n",
        "# Formatting\n",
        "plt.axhline(y=0, color='black', linewidth=1)  # Zero line for reference\n",
        "plt.axhline(y=threshold, color='red', linestyle='--', label='Severe Drought Threshold (-1.5)')\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"SPEI-9 Index\")\n",
        "plt.title(\"Monthly SPEI-9 Over Time (1992-2021)\")\n",
        "#plt.ylim(-2, 2)\n",
        "\n",
        "# Improve x-axis ticks to show years only\n",
        "years = pd.date_range(start=df['Date'].min(), end=df['Date'].max(), freq='YS')\n",
        "plt.xticks(years, [y.strftime('%Y') for y in years], rotation=45)\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JlajYtOK7o6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startDate = ee.Date(wf_startDate)\n",
        "endDate = ee.Date(wf_endDate)\n",
        "\n",
        "#retrive lat and long to get the adequate CRS for a correct area calculation\n",
        "latitude, longitude = get_shapefile_centroid(gdf)\n",
        "#print(f\"Central Point: ({latitude}, {longitude})\")\n",
        "best_epsg = get_best_crs(latitude, longitude)\n",
        "print(best_epsg)\n",
        "#calculate total area\n",
        "gdf_crs = gdf.to_crs(best_epsg)\n",
        "total_area_ha = (gdf_crs['geometry'].area/10000).sum()\n",
        "\n",
        "# buffered area\n",
        "gdf_buffered = gdf_crs.buffer(10000) # 10km buffer\n",
        "total_area_buffered_ha = (gdf_buffered.area/10000).sum()\n",
        "gdf_buffered_df = gpd.GeoDataFrame(geometry=gdf_buffered, crs=best_epsg)\n",
        "\n",
        "#print\n",
        "print(f'Total project area: {total_area_ha:.2f} ha')\n",
        "print(f'Total project area with 10km buffer: {total_area_buffered_ha:.2f} ha')\n",
        "\n",
        "# Convert to an Earth Engine object\n",
        "region = geemap.geopandas_to_ee(gdf_buffered_df)\n",
        "\n",
        "# MODIS Burned Area dataset\n",
        "sst = ee.ImageCollection(\"MODIS/061/MCD64A1\") \\\n",
        "            .select('BurnDate') \\\n",
        "            .filterDate(startDate, endDate)\n",
        "\n",
        "# calculate number of years to process\n",
        "nYears = ee.Number(endDate.difference(startDate, 'year')).round().subtract(1)\n",
        "#print(f'Number of years: {nYears.getInfo()}')\n",
        "\n",
        "# processs burned area per year\n",
        "byYear = ee.FeatureCollection(\n",
        "    ee.List.sequence(0, nYears).map(lambda n: process_year(n, region))\n",
        ")\n",
        "\n",
        "#features from the Earth Engine FeatureCollection\n",
        "features = byYear.getInfo()['features']\n",
        "\n",
        "#'area_ha' values and their corresponding years\n",
        "data = []\n",
        "for feature in features:\n",
        "    year = feature['id']  # The id corresponds to the year index (0-9 in your case)\n",
        "    area_ha = feature['properties']['burned_area_ha']\n",
        "    data.append({'year': int(year), 'burned_area_ha': area_ha})\n",
        "\n",
        "#convert to pandas dataframe\n",
        "df_wf = pd.DataFrame(data)\n",
        "#print(df_wf)\n",
        "\n",
        "#add new column to the df with the percentage of burned area per year\n",
        "df_wf['burned_area_percentage'] = (df_wf['burned_area_ha'] / total_area_buffered_ha) * 100\n",
        "\n",
        "# Calculate mean and standard deviation for area burned in hectares\n",
        "mean_area_percentage = df_wf['burned_area_percentage'].mean()\n",
        "std_area_percentage = df_wf['burned_area_percentage'].std()\n",
        "\n",
        "# Step 1: Identify big fire years\n",
        "df_wf['is_big_fire_year'] = df_wf['burned_area_percentage'] > 5 #(mean_area_percentage + std_area_percentage)\n",
        "df_wf['is_medium_fire_year'] = (df_wf['burned_area_percentage'] > 2) & (df_wf['burned_area_percentage'] <= 5)\n",
        "# Step 2: Calculate frequency of big fire years\n",
        "big_fire_frequency = df_wf['is_big_fire_year'].mean() * 100  # Frequency in percentage\n",
        "medium_fire_frequency = df_wf['is_medium_fire_year'].mean() * 100  # Frequency in percentage\n",
        "nr_big_fire_years = df_wf['is_big_fire_year'].sum()\n",
        "nr_medium_fire_years = df_wf['is_medium_fire_year'].sum()\n",
        "\n",
        "# Step 3: Classify fire risk\n",
        "if mean_area_percentage < 2:\n",
        "    if nr_big_fire_years >= 1:\n",
        "        risk_level_wf = \"High risk\"\n",
        "    if nr_medium_fire_years >= 1:\n",
        "        risk_level_wf = \"Medium risk\"\n",
        "    else:\n",
        "        risk_level_wf = \"Low risk\"\n",
        "elif 2 <= mean_area_percentage <= 5:\n",
        "    if nr_big_fire_years >= 1:\n",
        "        risk_level_wf = \"High risk\"\n",
        "    if nr_medium_fire_years >= 1:\n",
        "        risk_level_wf = \"Medium risk\"\n",
        "    else:\n",
        "        risk_level_wf = \"Medium risk\"\n",
        "else:\n",
        "    risk_level_wf = \"High risk\"\n",
        "\n",
        "print(color.BOLD + 'WILDFIRES 2000-2024' + color.END)\n",
        "print(f\"Mean burned area: {mean_area_percentage:.2f}%\")\n",
        "print(f\"Frequency of big fire years: {big_fire_frequency:.2f}%\")\n",
        "print(f\"Freqeuncy of medium fire years: {medium_fire_frequency:.2f}%\")\n",
        "print(color.PURPLE + f\"Fire Risk Level: {risk_level_wf}\" + color.END)\n",
        "\n",
        "# Define risk thresholds\n",
        "low_risk_threshold = 2  # Low risk threshold (10%)\n",
        "high_risk_threshold = 5  # High risk threshold (30%)\n",
        "mean_threshold = mean_area_percentage  # Mean burned area percentage\n",
        "\n",
        "# Add a column for point size (optional, for visualization purposes)\n",
        "df_wf['point_size'] = df_wf['burned_area_percentage'] * 10  # Scale size for better visualization\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.scatterplot(\n",
        "    data=df_wf,\n",
        "    x='year',\n",
        "    y='burned_area_percentage',\n",
        "    size='point_size',\n",
        "    hue='burned_area_percentage',\n",
        "    palette='coolwarm',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "# Add horizontal lines for risk thresholds\n",
        "plt.axhline(y=low_risk_threshold, color='green', linestyle='--', label='Low Risk Threshold (2%)')\n",
        "plt.axhline(y=high_risk_threshold, color='red', linestyle='--', label='High Risk Threshold (5%)')\n",
        "plt.axhline(y=mean_threshold, color='blue', linestyle='-', label=f'Mean Burned Area ({mean_threshold:.2f}%)')\n",
        "\n",
        "# Set labels and title\n",
        "plt.title(f'Percentage of Burned Area per Year with Risk Thresholds', fontsize=16)\n",
        "plt.xlabel('Year', fontsize=14)\n",
        "plt.ylabel('Burned Area (%)', fontsize=14)\n",
        "\n",
        "# Set y-axis limits\n",
        "plt.ylim(0, df_wf['burned_area_percentage'].max() * 1.1)\n",
        "\n",
        "# Show legend\n",
        "plt.legend(loc='upper right', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OeHb4jyP7rBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MODIS Burned Area dataset and filter by date\n",
        "burned = (\n",
        "    ee.ImageCollection(\"MODIS/061/MCD64A1\")\n",
        "    .select('BurnDate')\n",
        "    .filterDate(startDate, endDate)\n",
        ")\n",
        "\n",
        "# Convert BurnDate values into a binary burn occurrence (1 for burned, 0 otherwise)\n",
        "burned_binary = burned.map(lambda img: img.gt(0).unmask(0))\n",
        "\n",
        "# Sum the occurrences of burned areas over time\n",
        "burn_count = burned_binary.sum().clip(region)\n",
        "\n",
        "# Get the statistics of burn_count over the region\n",
        "burn_stats = burn_count.reduceRegion(\n",
        "    reducer=ee.Reducer.minMax().combine(\n",
        "        ee.Reducer.mean(), sharedInputs=True\n",
        "    ).combine(\n",
        "        ee.Reducer.stdDev(), sharedInputs=True\n",
        "    ),\n",
        "    geometry=region,\n",
        "    scale=500,  # MODIS resolution is ~500m\n",
        "    bestEffort=True\n",
        ")\n",
        "\n",
        "\n",
        "burnDate_max = burn_stats.get('BurnDate_max')\n",
        "burnDate_min = burn_stats.get('BurnDate_min')\n",
        "#print(burn_stats.getInfo())\n",
        "\n",
        "gdf = gpd.read_file(input_shp).to_crs('EPSG:4326')\n",
        "region_o = geemap.geopandas_to_ee(gdf)\n",
        "\n",
        "# Retrieve the actual min and max values as Python numbers\n",
        "burnDate_min_val = burnDate_min.getInfo()\n",
        "burnDate_max_val = burnDate_max.getInfo()\n",
        "\n",
        "# Define visualization parameters using actual numeric values\n",
        "vis_params = {\n",
        "    'min': burnDate_min_val,\n",
        "    'max': burnDate_max_val,\n",
        "    'palette': ['white', '#FFFFB2', '#FECC5C', '#FD8D3C', '#E31A1C']  # YlOrRd_04 color palette\n",
        "}\n",
        "print(f\"Min Burn Date: {burnDate_min_val}\")\n",
        "print(f\"Max Burn Date: {burnDate_max_val}\")\n",
        "# Create an interactive map\n",
        "Map = geemap.Map()\n",
        "\n",
        "# Center the map around your region\n",
        "Map.centerObject(region, 11)\n",
        "# Add the burn frequency layer\n",
        "Map.addLayer(burn_count, vis_params, \"Burn Frequency\")\n",
        "fc = region.style(fillColor='00000000')  # Transparent fill for 'region'\n",
        "Map.addLayer(fc, {}, \"Transparent Region Boundary\")\n",
        "#region original\n",
        "fc_o = region_o.style(fillColor='00000000')  # Transparent fill for 'region_o'\n",
        "Map.addLayer(fc_o, {}, \"Transparent Region O Boundary\")\n",
        "Map.add_colorbar(\n",
        "    vis_params=vis_params,\n",
        "    label=\"Fire Frequency (years)\",\n",
        "    orientation=\"horizontal\"\n",
        ")\n",
        "# Display the map\n",
        "Map"
      ],
      "metadata": {
        "id": "pvjePHax7t_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tif to Google Drive\n",
        "geemap.ee_export_image_to_drive(\n",
        "    burn_count, description=f'burned_frequency_{project_name}', region=region.geometry(), scale=30\n",
        ")"
      ],
      "metadata": {
        "id": "piPYEjjp7xx1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}